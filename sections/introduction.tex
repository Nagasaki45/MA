\section{Introduction and framework}

% Covering the history of music technology and interactive music system.
% Don't enter into mobile devices, social networks, indoor positioning or location based services, keep them to the literature review or to the system development chapter.
% Add a paragraph for short survey of AR.

In the past 60 years the development of new technology has fundamentally transformed music creation and consumption (Winkler, 2001: \todo{what page?}). Today, interactive music systems are used in many different contexts ranging from instrument design to socially interactive installations (Drummond, 2009). In this work I will focus on the new possibilities that real-time social interaction\new{, with the help of modern mobile technology,} can offer to \st{interactive} music consumption. \st{I will describe the history of music interactive systems and show different relevant works by other researchers.} \new{I will start with an historic review of the field of interactive music systems with emphasis on key events and important projects.}

\st{Furthermore, the field of music interactive systems is closely related to other fields of research that will be important for my work as well. Among these are social interaction and social media (Kaplan and Haenlein, 2010), augmented reality (Azuma, 1997), positioning technology (``Positioning technology''), location based services (Schiller and Voisard, 2004) and more.}

Since the beginning of the exploration \new{in the field} of \new{interactive} music \st{interactive} system\new{s} in the nineteen-sixties, different researchers and composers created systems that were able to interact with performer in a live situation. First examples of this kind of \st{interactive music} \st{are} \new{interaction} \new{were} Gordon Mumma's Hornpipe, and Morton Subotnick's Touch (\href{http://blog.lib.umn.edu/geers001/emusic/14_assig_ComposingInteractiveMusicCh1-2.pdf}{Winkler, 2001: 12})\new{, where specially designed electronic systems alter the input from the performer in some nondeterministic, yet musically defined, manner}. Later, programming languages designed for musical applications began to be developed, such as GROOVE by Max Mathews and Richard Moore at Bell labs (Mathews and Moore, 1970). \new{Using those languages musicians was able to create system like those of Mumma and Subotnick programmatically}.

In the nineteen-eighties, a group of musical instruments manufacturers agreed on standard method for sending and receiving musical information digitally, establishing \new{the }MIDI \new{protocol} as a universal standard (\href{http://www.insidetechnology360.com/index.php/the-history-of-midi-8862/}{Quinn, 2010}). The standardization of sending and receiving information combined with the emergence of personal computers enabled the creation of \st{commercial and open source} \new{modern} programing languages for musical application\new{s}\st{, the most important one today is}. Max/MSP (\href{http://cycling74.com/whatismax/}{\st{``What is Max?''}}) \new{which began its development} by Miller Puckette \st{from IRCAM, Paris} in 1986 \new{may be a good example} (\href{http://blog.lib.umn.edu/geers001/emusic/14_assig_ComposingInteractiveMusicCh1-2.pdf}{Winkler, 2001: 16}). \new{As opposed to early programming languages as GROOVE, most of those personal computer based languages not only still exist today but also keep progressing and new music oriented programing languages are written every year} (\todo{reference ChucK}).\st{ One of the main uses of these new programming languages was to compose interactive music that can manipulate sound during performance in real-time.}

\new{But the proliferation of the personal computer not only drive the creation of programing languages for music application. In the nineteen-nineties} \st{Due to new opportunities in digital signal processing technologies in the nineteen-nineties, and the proliferation of personal computers,} digital audio workstations (DAW) became a common alternative to analog recording \new{equipment} \st{systems} in \st{recording} studios (\todo{find reference}). Later, with the arrival of the VST standard (\href{http://www.steinberg.net/en/company/technologies.html}{``Steinberg technologies''}) \st{and Ableton Live (}\href{https://www.ableton.com/en/live/}{\st{``What is Live?''}}), computers became \new{even more essential tool for music production.} \st{the main tool for audio manipulation in real time.} \new{Those changes also find their way to the stage with the emergence of live performance oriented DAWs as Ableton Live (}\href{https://www.ableton.com/en/live/}{\new{``What is Live?''}}\new{) and software based DJ setups in late nineteen-nineties.} 

\new{Another key event in the history of interactive music systems is the appearance of the Arduino platform in 2006. The Arduino is an easy to use hardware and software package, ``intended for artists, designers, hobbyists and anyone interested in creating interactive objects or environments.'' (}\todo{Arduino homepage ref here}\new{) Until its appearance the only way for a musician to interact with music creation software was through audio and MIDI. But from then }\st{When microcontrollers like the Arduino platform (``Arduino'') began to appear in mid 2000's} a lot of new ways of controlling audio started to be possible, mostly by translating physical properties of the space into sound.

Today, one can find the cutting edge research in music interactive systems and the exploration of new ways of music creation and music expression in ambitious projects like the Multimodal Brain Orchestra (\href{http://specs.upf.edu/installation/2025}{\todo{reference madrid SPECS group}}) and Urban Musical Games (\href{http://imtr.ircam.fr/imtr/IRCAM_Real-Time_Musical_Interactions}{``IRCAM real-time musical interactions''}).

\new{On the other hand, }with the emergence of modern mobile devices, interactive music systems have become accessible to non-musicians (for example AutoRap by Smule [4], and RjDj [5]) as well as facilitating a shared process of music creation between different users in social context [6-7].

\new{Another key concept with high relevance to my work is Augmented Reality (AR). According to Azuma, AR systems integrate 3-D virtual objects into a 3-D real environment in real time (1997). Given this necessarily visual definition it is clear that there is no way to accomplish ``Audio-Only'' AR system. Later in his article Azuma states that ``AR enhances a user's perception of and interaction with the real world'', a statement which lighten the subject in much broader manner and open the door to enhance ones perception of and interaction with the world with much more than just visual information.}